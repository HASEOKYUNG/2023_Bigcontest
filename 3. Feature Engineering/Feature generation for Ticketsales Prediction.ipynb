{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c365f5",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de73e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# W2V\n",
    "import re\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ignore warnings\n",
    "import warnings ; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11916125",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fc07cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('../data/DataCleansing_final.pqt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e47ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 장르별 Clustering 결과를 불러온다.\n",
    "symphony = pd.read_csv('../data/ClusteringResult/symphony_clustering.csv')\n",
    "data_symphony = data.merge(symphony[['performance_label','seat_label','cluster']], on=['performance_label','seat_label'])\n",
    "\n",
    "chorus = pd.read_csv('../data/ClusteringResult/chorus_clustering.csv')\n",
    "data_chorus = data.merge(chorus[['performance_label','seat_label','cluster']], on=['performance_label','seat_label'])\n",
    "\n",
    "voice = pd.read_csv('../data/ClusteringResult/voice_clustering.csv')\n",
    "data_voice = data.merge(voice[['performance_label','seat_label','cluster']], on=['performance_label','seat_label'])\n",
    "\n",
    "solo = pd.read_csv('../data/ClusteringResult/solo_clustering.csv')\n",
    "data_solo = data.merge(solo[['performance_label','seat_label','cluster']], on=['performance_label','seat_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ade99",
   "metadata": {},
   "source": [
    "## Feature Generation\n",
    "장르별 Clustering 결과에 Feature Generation 함수를 적용할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c0c088",
   "metadata": {},
   "source": [
    "- 기초 Features<br>\n",
    "  : 공연년도, 공연월, 공연시간, 공연요일, 예매년도, 예매월, 선예매기간, 동월 해당장르 공연수, 동월 전체 공연 대비 해당 장르 공연수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc3d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_features(DATA):\n",
    "    ease = DATA.drop_duplicates('performance_label')\\\n",
    "           [['performance_label','play_year','play_month','play_time','play_weekday','open_year','open_month',\n",
    "             'pre_open_gap','open_gap','running_time','intermission','n_grade']]\n",
    "    # 월별 공연수, 타공연대비 비율\n",
    "    month = DATA.groupby(['play_year','play_month'])['performance_label'].nunique().rename('n_performance_month')\n",
    "    month = pd.concat([month, \n",
    "                       month.divide(data.groupby(['play_year','play_month'])['performance_label'].nunique().loc[month.index]).rename('n_performance_rate')], axis=1)\n",
    "    ease = ease.merge(month.reset_index(),\n",
    "                      on=['play_year','play_month']).set_index('performance_label').sort_index()\n",
    "    return ease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85123103",
   "metadata": {},
   "source": [
    "- 가격 관련 Features<br>\n",
    "  : 등급별 가격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27d1a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_features(DATA):\n",
    "    grade = DATA.dropna(subset=['origin_price']).query('origin_price != 0')\\\n",
    "           .groupby('performance_label')['origin_price'].unique()\n",
    "    grade = grade.apply(lambda x: sorted(x, reverse=True)+[0]*(5-len(x)))\n",
    "    grade = pd.DataFrame([*grade.values], index=grade.index, columns=[f'G{i}' for i in range(1,6)])//1000\n",
    "    \n",
    "    rate = DATA.groupby(['play_date','performance_label'])[['price','origin_price']].sum().cumsum()\n",
    "    rate['price_rate'] = rate['price']/rate['origin_price']\n",
    "    rate = pd.Series(np.append(np.nan, \n",
    "                               rate['price_rate'].iloc[:-1].reset_index(drop=True)\\\n",
    "                               .divide(pd.Series(range(1, len(rate))), axis=0).values.flatten()),\n",
    "                     index=rate.index,name='price_rate').fillna(0)\n",
    "    return pd.concat([grade, rate.reset_index().set_index('performance_label')['price_rate']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a11f76",
   "metadata": {},
   "source": [
    "- 날짜 간격 관련 Features<br>\n",
    "  :최초 100개 공연 매진까지 걸린 시간의 시계열평균, 예매와 공연일 차이의 시계열평균 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72812527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gap_features(DATA):\n",
    "    tran = DATA.groupby(['play_date','performance_label'])[['tran_gap']].agg(lambda x: np.mean(sorted(x[:100])))\n",
    "    tran['100_tran_gap'] = pd.Series(np.append(np.nan, \n",
    "                                     tran.cumsum()[:-1].reset_index(drop=True)\\\n",
    "                                     .divide(pd.Series(range(1, len(tran))), axis=0).values.flatten()),index=tran.index)\n",
    "    tran['100_tran_gap'].fillna(tran['100_tran_gap'].iloc[:3].mean(), inplace=True)\n",
    "    \n",
    "    play = DATA.groupby(['play_date','performance_label'])[['play_gap']].mean()\n",
    "    play['play_gap'] = pd.Series(np.append(np.nan, \n",
    "                                           play.cumsum()[:-1].reset_index(drop=True)\\\n",
    "                                           .divide(pd.Series(range(1, len(play))), axis=0).values.flatten()),index=play.index)\n",
    "    play['play_gap'].fillna(play['play_gap'].iloc[:3].mean(), inplace=True)\n",
    "    \n",
    "    return pd.concat([tran.reset_index().set_index('performance_label')['100_tran_gap'],\n",
    "                       play.reset_index().set_index('performance_label')['play_gap']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d9346",
   "metadata": {},
   "source": [
    "- 공연명 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b72368f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def W2V(DATA):\n",
    "    ease = DATA.drop_duplicates('performance_label').set_index('performance_label').sort_index()[['공연명전처리']]\n",
    "    ease = ease.dropna(subset=['공연명전처리'])\n",
    "    # 토큰화\n",
    "    data_words = [word_tokenize(title) for title in ease['공연명전처리'].dropna()]\n",
    "    # TaggedDocument 객체 생성\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(data_words)]\n",
    "\n",
    "    # Doc2Vec 모델 초기화\n",
    "    model = Doc2Vec(vector_size=2, window=2, min_count=1, workers=4, epochs=100)\n",
    "    # 모델 어휘 구축\n",
    "    model.build_vocab(documents)\n",
    "    # 모델 훈련\n",
    "    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "    return pd.DataFrame([model.infer_vector(doc_words) for i, doc_words in enumerate(data_words)], \n",
    "                         index=ease.index, columns=['vector_{}'.format(i) for i in range(model.vector_size)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3d668",
   "metadata": {},
   "source": [
    "- 클러스터 관련 Features<br>\n",
    "  :클러스터별 평균 예매수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acdd9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_features(DATA):\n",
    "    meansale = pd.DataFrame()\n",
    "    for c in DATA.cluster.unique():\n",
    "        ease = DATA.query('cluster == @c').groupby(['play_date','performance_label'])[['seat_label']].agg(pd.Series.nunique)\n",
    "        ease['meansale'] = pd.Series(np.append(np.nan, \n",
    "                                   ease.cumsum()[:-1].reset_index(drop=True)\\\n",
    "                                   .divide(pd.Series(range(1, len(ease))), axis=0).values.flatten()), index=ease.index)\n",
    "        ease['meansale'].fillna(ease['meansale'].iloc[:3].mean(), inplace=True)\n",
    "        ease['cluster'] = c\n",
    "        meansale = pd.concat([meansale, ease])\n",
    "    meansale = meansale.reset_index().set_index('performance_label')[['seat_label','meansale','cluster']].rename(columns={'seat_label':'TARGET'})\n",
    "    meansale = pd.concat([meansale, pd.get_dummies(meansale['cluster'], prefix='cluster', dtype=int)], axis=1)\n",
    "    meansale.drop('cluster', axis=1, inplace=True)\n",
    "    return meansale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db8941",
   "metadata": {},
   "source": [
    "## Merge features & target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8444b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: (1206, 30)\n"
     ]
    }
   ],
   "source": [
    "# 교향곡\n",
    "symphony_feature = cluster_features(data_symphony).reset_index()\\\n",
    "                   .merge(pd.concat([basic_features(data_symphony), price_features(data_symphony), \n",
    "                                     gap_features(data_symphony), W2V(data_symphony)], axis=1).reset_index(),\n",
    "                          on='performance_label').set_index('performance_label')\n",
    "print(f'데이터 크기: {symphony_feature.shape}')\n",
    "\n",
    "# 결측치를 처리한다.\n",
    "symphony_feature[['G1', 'G2', 'G3', 'G4', 'G5']] = symphony_feature[['G1', 'G2', 'G3', 'G4', 'G5']].fillna(-1)\n",
    "symphony_feature.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6093a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: (250, 30)\n"
     ]
    }
   ],
   "source": [
    "# 합창\n",
    "chorus_feature = cluster_features(data_chorus).reset_index()\\\n",
    "                 .merge(pd.concat([basic_features(data_chorus), price_features(data_chorus), \n",
    "                                   gap_features(data_chorus), W2V(data_chorus)], axis=1).reset_index(),\n",
    "                        on='performance_label').set_index('performance_label')\n",
    "print(f'데이터 크기: {chorus_feature.shape}')\n",
    "\n",
    "# 결측치를 처리한다.\n",
    "chorus_feature[['G1', 'G2', 'G3', 'G4', 'G5']] = chorus_feature[['G1', 'G2', 'G3', 'G4', 'G5']].fillna(-1)\n",
    "chorus_feature.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1c568eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: (96, 30)\n"
     ]
    }
   ],
   "source": [
    "# 성악\n",
    "voice_feature = cluster_features(data_voice).reset_index()\\\n",
    "               .merge(pd.concat([basic_features(data_voice), price_features(data_voice), \n",
    "                                 gap_features(data_voice), W2V(data_voice)], axis=1).reset_index(),\n",
    "                      on='performance_label').set_index('performance_label')\n",
    "print(f'데이터 크기: {voice_feature.shape}')\n",
    "\n",
    "# 결측치를 처리한다.\n",
    "voice_feature[['G1', 'G2', 'G3', 'G4', 'G5']] = voice_feature[['G1', 'G2', 'G3', 'G4', 'G5']].fillna(-1)\n",
    "voice_feature.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92731bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: (217, 31)\n"
     ]
    }
   ],
   "source": [
    "# 독주\n",
    "solo_feature = cluster_features(data_solo).reset_index()\\\n",
    "               .merge(pd.concat([basic_features(data_solo), price_features(data_solo), \n",
    "                                 gap_features(data_solo), W2V(data_solo)], axis=1).reset_index(),\n",
    "                      on='performance_label').set_index('performance_label')\n",
    "print(f'데이터 크기: {solo_feature.shape}')\n",
    "\n",
    "# 결측치를 처리한다.\n",
    "solo_feature[['G1', 'G2', 'G3', 'G4', 'G5']] = solo_feature[['G1', 'G2', 'G3', 'G4', 'G5']].fillna(-1)\n",
    "solo_feature.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d36dd",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a9613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((symphony_feature, chorus_feature, voice_feature, solo_feature), \n",
    "            open(f'../data/Feature/Feature_230922.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03dff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
